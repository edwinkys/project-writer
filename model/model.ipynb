{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit382pyenv1518160d034e4ba6ab51bd99c9504900",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions\n",
    "\n",
    "This notebook contains the functions that is needed for the production model for the web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Notebook\n",
    "Run all of the command below to start the notebook training session of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to kill the runtime in Google Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill -9 -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to install necessary file in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "# !pip install gpt_2_simple\n",
    "# !nvidia-smi\n",
    "# !mkdir -p datasets\n",
    "# !mkdir -p checkpoint\n",
    "# !mkdir -p samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to download the model in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpt_2_simple as gpt2\n",
    "# gpt2.download_gpt2(model_name='124M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Scrapping\n",
    "\n",
    "This function is used for scrapping all the text that is contains within a certain website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract():\n",
    "    def __init__(self, urls, return_as_file=True):\n",
    "        self.urls = urls  # List of urls for the dataset\n",
    "        self.return_as_file = return_as_file  # Export the dataset as a file\n",
    "\n",
    "    def remove_blank_lines(self, paragraph):\n",
    "        '''\n",
    "\n",
    "        Function to remove extra blank lines in a paragraphs.\n",
    "\n",
    "        @paragraph: A list of string\n",
    "\n",
    "        return: A paragraph without extra blank lines\n",
    "\n",
    "        '''\n",
    "\n",
    "        lines = paragraph.split('\\n')\n",
    "\n",
    "        non_empty_lines = [line for line in lines if line.strip() != '']\n",
    "\n",
    "        string_without_empty_lines = ''\n",
    "        for line in non_empty_lines:\n",
    "            string_without_empty_lines += line + '\\n'\n",
    "\n",
    "        return string_without_empty_lines\n",
    "\n",
    "    def extract_from_investopedia(self):\n",
    "        '''\n",
    "\n",
    "        Function to extract the text in the list of urls of Investopedia.\n",
    "\n",
    "        return: String containing text from urls\n",
    "\n",
    "        '''\n",
    "\n",
    "        # List of elements containing text\n",
    "        elements = [\n",
    "            'article'\n",
    "        ]\n",
    "\n",
    "        # List of elements to delete\n",
    "        delete_elements = [\n",
    "            'header',\n",
    "            'span',\n",
    "            'footer'\n",
    "        ]\n",
    "\n",
    "        # Initialize string container\n",
    "        texts = ''\n",
    "\n",
    "        # Loop over the urls\n",
    "        for url in self.urls:\n",
    "            page = urlopen(url).read()\n",
    "\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "            # Delete some elements\n",
    "            for element in soup(delete_elements):\n",
    "                element.decompose()\n",
    "\n",
    "            # Remove useless div\n",
    "            for div in soup.find_all('div', ['breadcrumbs']): \n",
    "                div.decompose()\n",
    "\n",
    "            list_text_tags = soup.find_all(elements)\n",
    "\n",
    "            for tag in list_text_tags:\n",
    "                text = tag.text\n",
    "\n",
    "                # Remove extra spaces\n",
    "                text = text.strip()\n",
    "\n",
    "                # Add the text to the container\n",
    "                texts += text\n",
    "\n",
    "        # Remove extra spaces\n",
    "        texts = self.remove_blank_lines(texts)\n",
    "        texts = texts.strip()\n",
    "\n",
    "        if self.return_as_file:\n",
    "            filename = 'dataset_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())  # Export a text file\n",
    "            path = r'./datasets/' + filename\n",
    "\n",
    "            # Write the text file in the datasets folder\n",
    "            with open(path, 'w') as f:\n",
    "                f.write(texts)\n",
    "\n",
    "        else:\n",
    "            return texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the text extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\nThe ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal.\nWhen most people hear the term artificial intelligence, the first thing they usually think of is robots. That's because big-budget films and novels weave stories about human-like machines that wreak havoc on Earth. But nothing could be further from the truth.\nArtificial intelligence is based on the principle that human intelligence can be defined in a way that a machine can easily mimic it and execute tasks, from the most simple to those that are even more complex. The goals of artificial intelligence include learning, reasoning, and perception.\nAs technology advances, previous benchmarks that defined artificial intelligence become outdated. For example, machines that calculate basic functions or recognize text through optimal character recognition are no longer considered to embody artificial intelligence, since this function is now taken for granted as an inherent computer function.\nAI is continuously evolving to benefit many different industries. Machines are wired using a cross-disciplinary approach based in mathematics, computer science, linguistics, psychology, and more.\nAlgorithms often play a very important part in the structure of artificial intelligence, where simple algorithms are used in simple applications, while more complex ones help frame strong artificial intelligence.\nThe applications for artificial intelligence are endless. The technology can be applied to many different sectors and industries. AI is being tested and used in the healthcare industry for dosing drugs and different treatment in patients, and for surgical procedures in the operating room.\nOther examples of machines with artificial intelligence include computers that play chess and self-driving cars. Each of these machines must weigh the consequences of any action they take, as each action will impact the end result. In chess, the end result is winning the game. For self-driving cars, the computer system must account for all external data and compute it to act in a way that prevents a collision.\nArtificial intelligence also has applications in the financial industry, where it is used to detect and flag activity in banking and finance such as unusual debit card usage and large account deposits—all of which help a bank's fraud department. Applications for AI are also being used to help streamline and make trading easier. This is done by making supply, demand, and pricing of securities easier to estimate.\nKey Takeaways\nArtificial intelligence refers to the simulation of human intelligence in machines.The goals of artificial intelligence include learning, reasoning, and perception.AI is being used across different industries including finance and healthcare.Weak AI tends to be simple and single-task oriented, while strong AI carries on tasks that are more complex and human-like.\nArtificial intelligence can be divided into two different categories: weak and strong. Weak artificial intelligence embodies a system designed to carry out one particular job. Weak AI systems include video games such as the chess example from above and personal assistants such as Amazon's Alexa and Apple's Siri. You ask the assistant a question, it answers it for you.\nStrong artificial intelligence systems are systems that carry on the tasks considered to be human-like. These tend to be more complex and complicated systems. They are programmed to handle situations in which they may be required to problem solve without having a person intervene. These kinds of systems can be found in applications like self-driving cars or in hospital operating rooms.\nSince its beginning, artificial intelligence has come under scrutiny from scientists and the public alike. One common theme is the idea that machines will become so highly developed that humans will not be able to keep up and they will take off on their own, redesigning themselves at an exponential rate.\nAnother is that machines can hack into people's privacy and even be weaponized. Other arguments debate the ethics of artificial intelligence and whether intelligent systems such as robots should be treated with the same rights as humans.\nSelf-driving cars have been fairly controversial as their machines tend to be designed for the lowest possible risk and the least casualties. If presented with a scenario of colliding with one person or another at the same time, these cars would calculate the option that would cause the least amount of damage.\nAnother contentious issue many people have with artificial intelligence is how it may affect human employment. With many industries looking to automate certain jobs through the use of intelligent machinery, there is a concern that people would be pushed out of the workforce. Self-driving cars may remove the need for taxis and car-share programs, while manufacturers may easily replace human labor with machines, making people's skills more obsolete.\n"
    }
   ],
   "source": [
    "# Function test\n",
    "extract = Extract(['https://www.investopedia.com/terms/a/artificial-intelligence-ai.asp'], return_as_file=False)\n",
    "test_investopedia_texts = extract.extract_from_investopedia()\n",
    "print(test_investopedia_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning Model\n",
    "This function is used to finetune the model based on the current latest dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(dataset):\n",
    "    '''\n",
    "\n",
    "    Function to finetune the model and save the trained model every checkpoint on the checkpoint folder.\n",
    "\n",
    "    @dataset: Path to the training data (TXT) with minimum 1024 tokens\n",
    "    @model_name: The name of the model: 124M, 355M, etc.\n",
    "    @learning_rate: The learning rate of the model\n",
    "\n",
    "    return: None\n",
    "\n",
    "    '''\n",
    "    # Parameters\n",
    "    STEPS = 1000\n",
    "    MODEL_NAME = '124M'\n",
    "    LEARNING_RATE = 0.0001\n",
    "\n",
    "    # Clear session graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Initialize training session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Finetune the model\n",
    "    gpt2.finetune(\n",
    "        sess,\n",
    "        dataset=dataset,  # Dataset CSV file\n",
    "        steps=STEPS,\n",
    "        model_name=MODEL_NAME,  # Model name: 124M, 355M, etc.\n",
    "        model_dir='models',\n",
    "        combine=50000,\n",
    "        batch_size=1,\n",
    "        learning_rate=LEARNING_RATE,  # Learning rate\n",
    "        accumulate_gradients=5,\n",
    "        restore_from='latest',  # Start training the model from the latest model\n",
    "        run_name='trained_model',  # Name of the trained model\n",
    "        checkpoint_dir='checkpoint',  # Directory to save the model\n",
    "        sample_every=250,\n",
    "        sample_length=500,  # Number of token generated\n",
    "        sample_num=1,\n",
    "        multi_gpu=False,\n",
    "        save_every=250,\n",
    "        print_every=10,\n",
    "        max_checkpoints=1,\n",
    "        use_memory_saving_gradients=False,\n",
    "        only_train_transformer_layers=False,\n",
    "        optimizer='adam',\n",
    "        overwrite=True  # Overwrite the current model when training\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the finetuning model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = ''\n",
    "# finetune_model(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text\n",
    "This functions is used to generate the text based on some input from the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(outline_to_length):\n",
    "    '''\n",
    "\n",
    "    Function to generate the text.\n",
    "\n",
    "    @outline_to_length: A 2D array containing the list of outline and the length desired\n",
    "        [[outline, length],\n",
    "        [outline, length],\n",
    "        [outline, length]]\n",
    "\n",
    "    return: List of generated text\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Clear session graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Initialize TensorFlow session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Create an empty list to store lists\n",
    "    essay = []\n",
    "\n",
    "    # Loop over the list\n",
    "    for record in outline_to_length:\n",
    "        prefix = record[0]  # The first sentence of the paragraph\n",
    "        length = record[1]  # The length of the paragraph (max: 1023)\n",
    "\n",
    "        text = gpt2.generate(\n",
    "            sess,\n",
    "            run_name='trained_model',\n",
    "            checkpoint_dir='checkpoint',\n",
    "            model_name=None,\n",
    "            model_dir='models',\n",
    "            sample_dir='samples',\n",
    "            return_as_list=True,  # Return as list of string\n",
    "            truncate=None,\n",
    "            destination_path=None,\n",
    "            sample_delim='\\n' + '=' * 20 + '\\n\\n',\n",
    "            prefix=prefix,\n",
    "            seed=None,\n",
    "            nsamples=1,  # Number of sample to be generated\n",
    "            batch_size=1,\n",
    "            length=length,\n",
    "            temperature=0.7,\n",
    "            top_k=0,\n",
    "            top_p=0.0,\n",
    "            include_prefix=True\n",
    "        )\n",
    "\n",
    "        essay += text\n",
    "\n",
    "        # Add double newline\n",
    "        essay += ['\\n\\n']\n",
    "\n",
    "    return ''.join(essay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_outline_to_length = [[]]\n",
    "# print(generate_text(test_outline_to_length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrasing Text\n",
    "This function is used to paraphrase the sentences to avoid direct plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Check\n",
    "This function is used to check and correct any grammatical error in the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}