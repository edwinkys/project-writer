{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit382pyenv1518160d034e4ba6ab51bd99c9504900",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions\n",
    "\n",
    "This notebook contains the functions that is needed for the production model for the web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Scrapping\n",
    "\n",
    "This function is used for scrapping all the text that is contains within a certain website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def extract_text(urls, export_as_file=True):\n",
    "    '''\n",
    "\n",
    "    Function to extract text from a website.\n",
    "\n",
    "    @urls: The list of website url\n",
    "    @export_as_file: Boolean to export the text result as a file\n",
    "\n",
    "    return: List of string or file containing the text\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    def remove_blank_lines(paragraph):\n",
    "        '''\n",
    "\n",
    "        Function to remove extra blank lines in a paragraphs.\n",
    "\n",
    "        @paragraph: A list of string\n",
    "\n",
    "        return: A paragraph without extra blank lines\n",
    "\n",
    "        '''\n",
    "\n",
    "        lines = paragraph.split('\\n')\n",
    "\n",
    "        non_empty_lines = [line for line in lines if line.strip() != '']\n",
    "\n",
    "        string_without_empty_lines = ''\n",
    "        for line in non_empty_lines:\n",
    "            string_without_empty_lines += line + '\\n'\n",
    "\n",
    "        return string_without_empty_lines\n",
    "\n",
    "\n",
    "    def clean_table_data(soup):\n",
    "        '''\n",
    "\n",
    "        Function to clean the table.\n",
    "\n",
    "        @soup: HTML page object from BeautifulSoup\n",
    "\n",
    "        return: Clean string containing table data\n",
    "\n",
    "        '''\n",
    "\n",
    "        table_elements = [\n",
    "        'table',\n",
    "        'thead',\n",
    "        'tbody',\n",
    "        'tfoot',\n",
    "        'tr',\n",
    "        'th',\n",
    "        'td'\n",
    "        ]\n",
    "\n",
    "        table_data = soup.find_all(table_elements, string=True)\n",
    "\n",
    "        string_table_data = ''\n",
    "        for data in table_data:\n",
    "            string_table_data += data.get_text() + ' '\n",
    "\n",
    "        return string_table_data\n",
    "\n",
    "\n",
    "    def delete_elements(soup, elements):\n",
    "        '''\n",
    "\n",
    "        Function to delete some elements.\n",
    "\n",
    "        @soup: HTML page object from BeautifulSoup\n",
    "        @elements: List of tags to delete\n",
    "\n",
    "        return: BeautifulSoup object without deleted elements\n",
    "\n",
    "        '''\n",
    "\n",
    "        for element in soup(elements):\n",
    "            element.decompose()\n",
    "\n",
    "        return soup\n",
    "\n",
    "    # List of elements to remove\n",
    "    elements = [\n",
    "        'head',\n",
    "        'script',\n",
    "        'style',\n",
    "        'header',\n",
    "        'nav',\n",
    "        'table',\n",
    "        'form',\n",
    "        'input',\n",
    "        'button',\n",
    "        'footer'\n",
    "    ]\n",
    "\n",
    "    # Initialize the dataframe\n",
    "    df = DataFrame(columns=['texts'])\n",
    "\n",
    "    # Loop over the list of urls\n",
    "    for url in urls:\n",
    "        page = urlopen(url).read()\n",
    "\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "        # Clean table\n",
    "        table_text = clean_table_data(soup)\n",
    "        soup = delete_elements(soup, elements)\n",
    "\n",
    "        # Fetch the text from the soup\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Clean the text\n",
    "        text = text.strip()\n",
    "        text = remove_blank_lines(text)\n",
    "\n",
    "        # Append the text to the dataframe\n",
    "        new_record = {'texts': text}\n",
    "        df = df.append(new_record, ignore_index=True)\n",
    "\n",
    "    # Export dataframe\n",
    "    if export_as_file:\n",
    "        filename = 'dataset_{:%Y%m%d_%H%M%S}.csv'.format(datatime.utcnow())\n",
    "        path = r'/datasets/' + filename\n",
    "        df.to_csv(path, index=False, header=False)\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "texts\n0  Zeus\\nFrom Wikipedia, the free encyclopedia\\nJ...\n"
    }
   ],
   "source": [
    "# Function test\n",
    "url = ['https://simple.wikipedia.org/wiki/Zeus']\n",
    "print(extract_text(url, export_as_file=False))"
   ]
  }
 ]
}