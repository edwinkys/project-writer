{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit382pyenv1518160d034e4ba6ab51bd99c9504900",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class\n",
    "\n",
    "This notebook contains the AI model to finetune and generate the essay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Notebook\n",
    "Run all of the command below to start the notebook training session of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to kill the runtime in Google Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill -9 -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to install necessary file in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "\n",
    "# !pip install gpt_2_simple\n",
    "# !pip install wikipedia\n",
    "\n",
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p drive/My\\ Drive/Project\\ Writer/datasets\n",
    "# !mkdir -p drive/My\\ Drive/Project\\ Writer/checkpoint\n",
    "# !mkdir -p drive/My\\ Drive/Project\\ Writer/samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to download the model in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpt_2_simple as gpt2\n",
    "# gpt2.download_gpt2(model_name='355M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gpt_2_simple as gpt2\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "This function is used to finetune the model based on the current latest dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(dataset, any_checkpoint=False, reset_session=False):\n",
    "    '''\n",
    "\n",
    "    Function to finetune the model and save the trained model every checkpoint on the checkpoint folder.\n",
    "\n",
    "    @dataset: Path to the training data (TXT) with minimum 1024 tokens\n",
    "    @any_checkpoint: Boolean if there is any previous checkpoint\n",
    "    @reset_session: Boolean if reseting the session graph is needed\n",
    "\n",
    "    return: None\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Parameters\n",
    "    STEPS = 10000\n",
    "    MODEL_NAME = '355M'\n",
    "    LEARNING_RATE = 0.0001\n",
    "    RUN_NAME = 'trained_model'\n",
    "\n",
    "    MODEL_DIR = 'models'\n",
    "    CHECKPOINT_DIR = 'checkpoint'\n",
    "\n",
    "    # Clear session graph\n",
    "    if reset_session:\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "    # Initialize training session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Load the previous checkpoint\n",
    "    if any_checkpoint:\n",
    "        gpt2.load_gpt2(\n",
    "            sess,\n",
    "            run_name=RUN_NAME,\n",
    "            checkpoint_dir=CHECKPOINT_DIR,\n",
    "            model_name=None,\n",
    "            model_dir=MODEL_DIR,\n",
    "            multi_gpu=False\n",
    "        )\n",
    "\n",
    "    # Finetune the model\n",
    "    gpt2.finetune(\n",
    "        sess,\n",
    "        dataset=dataset,  # Dataset file\n",
    "        steps=STEPS,\n",
    "        model_name=MODEL_NAME,  # Model name: 124M, 355M, etc.\n",
    "        model_dir=MODEL_DIR,\n",
    "        combine=50000,\n",
    "        batch_size=1,\n",
    "        learning_rate=LEARNING_RATE,  # Learning rate\n",
    "        accumulate_gradients=5,\n",
    "        restore_from='latest',  # Start training the model from the latest model\n",
    "        run_name=RUN_NAME,  # Name of the trained model\n",
    "        checkpoint_dir=CHECKPOINT_DIR,  # Directory to save the model\n",
    "        sample_every=1000,\n",
    "        sample_length=300,  # Number of token generated\n",
    "        sample_num=1,\n",
    "        multi_gpu=False,\n",
    "        save_every=1000,\n",
    "        print_every=10,\n",
    "        max_checkpoints=1,\n",
    "        use_memory_saving_gradients=False,\n",
    "        only_train_transformer_layers=False,\n",
    "        optimizer='adam',\n",
    "        overwrite=True  # Overwrite the current model when training\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the finetuning model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_training_data = ''\n",
    "# finetune_model(test_training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text\n",
    "This functions is used to generate the text based on some input from the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(outline_to_length):\n",
    "    '''\n",
    "\n",
    "    Function to generate the text.\n",
    "\n",
    "    @outline_to_length: A 2D array containing the list of outline and the length desired\n",
    "        [[outline, length],\n",
    "        [outline, length],\n",
    "        [outline, length]]\n",
    "\n",
    "    return: List of generated text\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Parameters\n",
    "    MODEL_NAME = '355M'\n",
    "    RUN_NAME = 'trained_model'\n",
    "\n",
    "    MODEL_DIR = 'models'\n",
    "    CHECKPOINT_DIR = 'checkpoint'\n",
    "    SAMPLE_DIR = 'samples'\n",
    "\n",
    "    # Clear session graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Initialize TensorFlow session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Create an empty list to store lists\n",
    "    essay = []\n",
    "\n",
    "    # Loop over the list\n",
    "    for record in outline_to_length:\n",
    "        prefix = record[0]  # The first sentence of the paragraph\n",
    "        length = record[1]  # The length of the paragraph (max: 1023)\n",
    "\n",
    "        text = gpt2.generate(\n",
    "            sess,\n",
    "            run_name=RUN_NAME,\n",
    "            checkpoint_dir=CHECKPOINT_DIR,\n",
    "            model_name=None,\n",
    "            model_dir=MODEL_DIR,\n",
    "            sample_dir=SAMPLE_DIR,\n",
    "            return_as_list=True,  # Return as list of string\n",
    "            truncate=None,\n",
    "            destination_path=None,\n",
    "            sample_delim='\\n\\n' + '=' * 20 + '\\n\\n',\n",
    "            prefix=prefix,\n",
    "            seed=None,\n",
    "            nsamples=1,  # Number of sample to be generated\n",
    "            batch_size=1,\n",
    "            length=length,\n",
    "            temperature=0.7,\n",
    "            top_k=0,\n",
    "            top_p=0.0,\n",
    "            include_prefix=True\n",
    "        )\n",
    "\n",
    "        text = ''.join(text) + '\\n\\n'\n",
    "        essay += text\n",
    "\n",
    "    return essay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_outline_to_length = [[]]\n",
    "# print(generate_text(test_outline_to_length))\n"
   ]
  }
 ]
}