{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit382pyenv1518160d034e4ba6ab51bd99c9504900",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class\n",
    "\n",
    "This notebook contains the AI model to finetune and generate the essay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Notebook\n",
    "Run all of the command below to start the notebook training session of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to kill the runtime in Google Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill -9 -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to install necessary file in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "\n",
    "# !pip install gpt_2_simple\n",
    "# !pip install wikipedia\n",
    "\n",
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p drive/My\\ Drive/Project\\ Writer/datasets\n",
    "# !mkdir -p drive/My\\ Drive/Project\\ Writer/checkpoint\n",
    "# !mkdir -p drive/My\\ Drive/Project\\ Writer/samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to download the model in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpt_2_simple as gpt2\n",
    "# gpt2.download_gpt2(model_name='355M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "This class is used to finetune the model and generate text based on the current latest dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    '''\n",
    "\n",
    "    Class to finetune the model and generate the text based on the dataset.\n",
    "\n",
    "    @sess: GPT-2 TensorFlow session\n",
    "    @model_name: The name of the model: 124M, 355M, etc.\n",
    "    @run_name: The name of the trained model for each run\n",
    "    @model_dir: The path to the directory containing the model\n",
    "    @checkpoint_dir: The path to the directory containing the previously trained model\n",
    "    @sample_dir: The path to the directory to save the sample\n",
    "    @steps: Number of iteration to train the model\n",
    "    @learning_rate: The rate of learning of the model\n",
    "\n",
    "    Methods:\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Import libraries\n",
    "    import gpt_2_simple as gpt2\n",
    "    import tensorflow as tf\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sess,\n",
    "        model_name,\n",
    "        run_name,\n",
    "        model_dir,\n",
    "        checkpoint_dir,\n",
    "        sample_dir,\n",
    "        steps=30000,\n",
    "        learning_rate=0.0001\n",
    "    ):\n",
    "        self.sess = sess\n",
    "        self.model_name = model_name\n",
    "        self.run_name = run_name\n",
    "        self.model_dir = model_dir\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.sample_dir = sample_dir\n",
    "        self.steps = steps\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def finetune_model(self, dataset):\n",
    "        '''\n",
    "        \n",
    "        Function to finetune the model and save the trained model every checkpoint on the checkpoint folder.\n",
    "\n",
    "        @sess: Tensorflow training session\n",
    "        @dataset: Path to the training dataset with minimum 1024 tokens\n",
    "\n",
    "        return: None\n",
    "\n",
    "        '''\n",
    "\n",
    "        gpt2.finetune(\n",
    "            self.sess,\n",
    "            dataset=dataset,  # Dataset file\n",
    "            steps=self.steps,\n",
    "            model_name=self.model_name,  # Model name: 124M, 355M, etc.\n",
    "            model_dir=self.model_dir,\n",
    "            combine=50000,\n",
    "            batch_size=1,\n",
    "            learning_rate=self.learning_rate,  # Learning rate\n",
    "            accumulate_gradients=5,\n",
    "            restore_from='latest',  # Start training the model from the latest model\n",
    "            run_name=self.run_name,  # Name of the trained model\n",
    "            checkpoint_dir=self.checkpoint_dir,  # Directory to save the model\n",
    "            sample_every=2500,\n",
    "            sample_length=300,  # Number of token generated\n",
    "            sample_num=1,\n",
    "            multi_gpu=False,\n",
    "            save_every=2500,\n",
    "            print_every=100,\n",
    "            max_checkpoints=1,\n",
    "            use_memory_saving_gradients=False,\n",
    "            only_train_transformer_layers=False,\n",
    "            optimizer='adam',\n",
    "            overwrite=True  # Overwrite the current model when training\n",
    "        )\n",
    "\n",
    "    def generate_text(self, outline_to_length):\n",
    "        '''\n",
    "\n",
    "        Function to generate the text.\n",
    "\n",
    "        @outline_to_length: A 2D array containing the list of outline and the length desired\n",
    "            [[outline, length],\n",
    "            [outline, length],\n",
    "            [outline, length]]\n",
    "\n",
    "        return: List of generated text\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Create an empty list to store lists\n",
    "        essay = []\n",
    "\n",
    "        # Loop over the list\n",
    "        for record in outline_to_length:\n",
    "            prefix = record[0]  # The first sentence of the paragraph\n",
    "            length = record[1]  # The length of the paragraph (max: 1023)\n",
    "\n",
    "            text = gpt2.generate(\n",
    "                self.sess,\n",
    "                run_name=self.run_name,\n",
    "                checkpoint_dir=self.checkpoint_dir,\n",
    "                model_name=None,\n",
    "                model_dir=self.model_dir,\n",
    "                sample_dir=self.sample_dir,\n",
    "                return_as_list=True,  # Return as list of string\n",
    "                truncate=None,\n",
    "                destination_path=None,\n",
    "                sample_delim='\\n\\n' + '=' * 10 + '\\n\\n',\n",
    "                prefix=prefix,\n",
    "                seed=None,\n",
    "                nsamples=1,  # Number of sample to be generated\n",
    "                batch_size=1,\n",
    "                length=length,  # Length of the generated text max: 1024 tokens\n",
    "                temperature=0.7,\n",
    "                top_k=0,\n",
    "                top_p=0.0,\n",
    "                include_prefix=True\n",
    "            )\n",
    "\n",
    "            text = ''.join(text) + '\\n\\n'\n",
    "            essay += text\n",
    "\n",
    "        return essay\n",
    "\n",
    "    def load_model(self):\n",
    "        '''\n",
    "\n",
    "        Function to load existing GPT-2 model.\n",
    "\n",
    "        return: None\n",
    "\n",
    "        '''\n",
    "\n",
    "        gpt2.load_gpt2(\n",
    "            self.sess,\n",
    "            run_name=self.run_name,\n",
    "            checkpoint_dir=self.checkpoint_dir,\n",
    "            model_name=None,\n",
    "            model_dir=self.model_dir,\n",
    "            multi_gpu=False,\n",
    "            reuse=True\n",
    "        )\n",
    "\n",
    "    def reset_session(self):\n",
    "        '''\n",
    "        \n",
    "        Function to reset the current TensorFlow session, to clear memory or load another model.\n",
    "\n",
    "        return: Reset session\n",
    "\n",
    "        '''\n",
    "\n",
    "        sess = gpt2.reset_session(self.sess)\n",
    "        return sess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(dataset, any_checkpoint=False, reset_session=False):\n",
    "    '''\n",
    "\n",
    "    Function to finetune the model and save the trained model every checkpoint on the checkpoint folder.\n",
    "\n",
    "    @dataset: Path to the training data (TXT) with minimum 1024 tokens\n",
    "    @any_checkpoint: Boolean if there is any previous checkpoint\n",
    "    @reset_session: Boolean if reseting the session graph is needed\n",
    "\n",
    "    return: None\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Parameters\n",
    "    STEPS = 10000\n",
    "    MODEL_NAME = '355M'\n",
    "    LEARNING_RATE = 0.0001\n",
    "    RUN_NAME = 'trained_model'\n",
    "\n",
    "    MODEL_DIR = 'models'\n",
    "    CHECKPOINT_DIR = 'checkpoint'\n",
    "\n",
    "    # Clear session graph\n",
    "    if reset_session:\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "    # Initialize training session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Load the previous checkpoint\n",
    "    if any_checkpoint:\n",
    "        gpt2.load_gpt2(\n",
    "            sess,\n",
    "            run_name=RUN_NAME,\n",
    "            checkpoint_dir=CHECKPOINT_DIR,\n",
    "            model_name=None,\n",
    "            model_dir=MODEL_DIR,\n",
    "            multi_gpu=False\n",
    "        )\n",
    "\n",
    "    # Finetune the model\n",
    "    gpt2.finetune(\n",
    "        sess,\n",
    "        dataset=dataset,  # Dataset file\n",
    "        steps=STEPS,\n",
    "        model_name=MODEL_NAME,  # Model name: 124M, 355M, etc.\n",
    "        model_dir=MODEL_DIR,\n",
    "        combine=50000,\n",
    "        batch_size=1,\n",
    "        learning_rate=LEARNING_RATE,  # Learning rate\n",
    "        accumulate_gradients=5,\n",
    "        restore_from='latest',  # Start training the model from the latest model\n",
    "        run_name=RUN_NAME,  # Name of the trained model\n",
    "        checkpoint_dir=CHECKPOINT_DIR,  # Directory to save the model\n",
    "        sample_every=1000,\n",
    "        sample_length=300,  # Number of token generated\n",
    "        sample_num=1,\n",
    "        multi_gpu=False,\n",
    "        save_every=1000,\n",
    "        print_every=10,\n",
    "        max_checkpoints=1,\n",
    "        use_memory_saving_gradients=False,\n",
    "        only_train_transformer_layers=False,\n",
    "        optimizer='adam',\n",
    "        overwrite=True  # Overwrite the current model when training\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the finetuning model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_training_data = ''\n",
    "# finetune_model(test_training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text\n",
    "This functions is used to generate the text based on some input from the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(outline_to_length):\n",
    "    '''\n",
    "\n",
    "    Function to generate the text.\n",
    "\n",
    "    @outline_to_length: A 2D array containing the list of outline and the length desired\n",
    "        [[outline, length],\n",
    "        [outline, length],\n",
    "        [outline, length]]\n",
    "\n",
    "    return: List of generated text\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Parameters\n",
    "    MODEL_NAME = '355M'\n",
    "    RUN_NAME = 'trained_model'\n",
    "\n",
    "    MODEL_DIR = 'models'\n",
    "    CHECKPOINT_DIR = 'checkpoint'\n",
    "    SAMPLE_DIR = 'samples'\n",
    "\n",
    "    # Clear session graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Initialize TensorFlow session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Create an empty list to store lists\n",
    "    essay = []\n",
    "\n",
    "    # Loop over the list\n",
    "    for record in outline_to_length:\n",
    "        prefix = record[0]  # The first sentence of the paragraph\n",
    "        length = record[1]  # The length of the paragraph (max: 1023)\n",
    "\n",
    "        text = gpt2.generate(\n",
    "            sess,\n",
    "            run_name=RUN_NAME,\n",
    "            checkpoint_dir=CHECKPOINT_DIR,\n",
    "            model_name=None,\n",
    "            model_dir=MODEL_DIR,\n",
    "            sample_dir=SAMPLE_DIR,\n",
    "            return_as_list=True,  # Return as list of string\n",
    "            truncate=None,\n",
    "            destination_path=None,\n",
    "            sample_delim='\\n\\n' + '=' * 20 + '\\n\\n',\n",
    "            prefix=prefix,\n",
    "            seed=None,\n",
    "            nsamples=1,  # Number of sample to be generated\n",
    "            batch_size=1,\n",
    "            length=length,\n",
    "            temperature=0.7,\n",
    "            top_k=0,\n",
    "            top_p=0.0,\n",
    "            include_prefix=True\n",
    "        )\n",
    "\n",
    "        text = ''.join(text) + '\\n\\n'\n",
    "        essay += text\n",
    "\n",
    "    return essay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_outline_to_length = [[]]\n",
    "# print(generate_text(test_outline_to_length))\n"
   ]
  }
 ]
}