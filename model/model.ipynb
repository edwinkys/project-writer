{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit382pyenv1518160d034e4ba6ab51bd99c9504900",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions\n",
    "\n",
    "This notebook contains the functions that is needed for the production model for the web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Notebook\n",
    "Run all of the command below to start the notebook training session of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to kill the runtime in Google Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill -9 -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to install necessary file in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "# !pip install gpt_2_simple\n",
    "# !nvidia-smi\n",
    "# !mkdir -p datasets\n",
    "# !mkdir -p checkpoint\n",
    "# !mkdir -p samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to download the model in Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpt_2_simple as gpt2\n",
    "# gpt2.download_gpt2(model_name='124M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Scrapping\n",
    "\n",
    "This function is used for scrapping all the text that is contains within a certain website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(urls, export_as_file=True):\n",
    "    '''\n",
    "\n",
    "    Function to extract text from a website.\n",
    "\n",
    "    @urls: The list of website url\n",
    "    @export_as_file: Boolean to export the text result as a file\n",
    "\n",
    "    return: List of string or file containing the text\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    def remove_blank_lines(paragraph):\n",
    "        '''\n",
    "\n",
    "        Function to remove extra blank lines in a paragraphs.\n",
    "\n",
    "        @paragraph: A list of string\n",
    "\n",
    "        return: A paragraph without extra blank lines\n",
    "\n",
    "        '''\n",
    "\n",
    "        lines = paragraph.split('\\n')\n",
    "\n",
    "        non_empty_lines = [line for line in lines if line.strip() != '']\n",
    "\n",
    "        string_without_empty_lines = ''\n",
    "        for line in non_empty_lines:\n",
    "            string_without_empty_lines += line + '\\n'\n",
    "\n",
    "        return string_without_empty_lines\n",
    "\n",
    "\n",
    "    def clean_table_data(soup):\n",
    "        '''\n",
    "\n",
    "        Function to clean the table.\n",
    "\n",
    "        @soup: HTML page object from BeautifulSoup\n",
    "\n",
    "        return: Clean string containing table data\n",
    "\n",
    "        '''\n",
    "\n",
    "        table_elements = [\n",
    "        'table',\n",
    "        'thead',\n",
    "        'tbody',\n",
    "        'tfoot',\n",
    "        'tr',\n",
    "        'th',\n",
    "        'td'\n",
    "        ]\n",
    "\n",
    "        table_data = soup.find_all(table_elements, string=True)\n",
    "\n",
    "        string_table_data = ''\n",
    "        for data in table_data:\n",
    "            string_table_data += data.get_text() + ' '\n",
    "\n",
    "        return string_table_data\n",
    "\n",
    "\n",
    "    def delete_elements(soup, elements):\n",
    "        '''\n",
    "\n",
    "        Function to delete some elements.\n",
    "\n",
    "        @soup: HTML page object from BeautifulSoup\n",
    "        @elements: List of tags to delete\n",
    "\n",
    "        return: BeautifulSoup object without deleted elements\n",
    "\n",
    "        '''\n",
    "\n",
    "        for element in soup(elements):\n",
    "            element.decompose()\n",
    "\n",
    "        return soup\n",
    "\n",
    "    # List of elements to remove\n",
    "    ELEMENTS = [\n",
    "        'head',\n",
    "        'script',\n",
    "        'style',\n",
    "        'header',\n",
    "        'nav',\n",
    "        'div',\n",
    "        'table',\n",
    "        'form',\n",
    "        'input',\n",
    "        'button',\n",
    "        'footer'\n",
    "    ]\n",
    "\n",
    "    # Initialize strings\n",
    "    texts = ''\n",
    "\n",
    "    # Loop over the list of urls\n",
    "    for url in urls:\n",
    "        page = urlopen(url).read()\n",
    "\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "        # Clean table\n",
    "        table_text = clean_table_data(soup)\n",
    "        soup = delete_elements(soup, ELEMENTS)\n",
    "\n",
    "        # Fetch the text from the soup\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Clean the text\n",
    "        text = text.strip()\n",
    "        text = remove_blank_lines(text)\n",
    "\n",
    "        # Append the text\n",
    "        texts += text\n",
    "\n",
    "    # Export dataframe\n",
    "    if export_as_file:\n",
    "        filename = 'dataset_{:%Y%m%d_%H%M%S}.txt'.format(datatime.utcnow())\n",
    "        path = r'./datasets/' + filename\n",
    "        \n",
    "        # Write the text file in the datasets folder\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(texts)\n",
    "\n",
    "    else:\n",
    "        return texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the text extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Zeus\nFrom Wikipedia, the free encyclopedia\nJump to navigation\nJump to search\nZeus is the god of the sky, lightning and the thunder in Ancient Greek religion and legends, and ruler of all the gods on Mount Olympus. Zeus is the sixth child of Cronos and Rhea, king and queen of the Titans. His father, Cronos, swallowed his children as soon as they were born for fear of a prophecy which foretold that one of them would overthrow him. When Zeus was born, Rhea hid him in a cave on Mount Ida in Crete, giving Cronos a stone wrapped in swaddling clothes to swallow instead. When Zeus was older he went to free his brothers and sisters; together with their allies, the Hekatonkheires and the Elder Cyclopes, Zeus and his siblings fought against the Titans in a ten-year war known as the Titanomachy. At the end of the war, Zeus took Cronos' scythe and cut him into pieces, throwing his remains into Tartarus. He then became the king of gods. \nThe supreme deity of the Greek pantheon, Zeus was universally respected and revered throughout Ancient Greece; the ancient Olympic Games were held at the site of  Olympia every four years in honor of him. Highly temperamental, Zeus was armed with the mighty thunderbolt, said to be the most powerful weapon among the gods. Zeus was married to his sister, Hera, though he was infamous for his infidelity, taking on an almost innumerable amount of lovers and consorts, both mortal and divine including Karis and Hercules' mother. Zeus was known for throwing thunderbolts at people. \nThe god of honor and justice, Zeus was the one who both established and enforced law, and served as the standard for kings to follow, ensuring they did not abuse the power of their position. His symbols were the thunderbolt, a sceptre, and oak tree, and the eagle and bull were his sacred animals. His Roman equivalent is Jupiter. Zeus was the strongest Greek god, the ruler of all gods. In Norse, Zeus is Odin.\nRelated pages[change | change source]\nTinia - Etruscan mythology version of Zeus\nOdin - Norse mythology version of Zeus\nJupiter - Roman mythology version of Zeus\nReferences[change | change source]\n↑ The sculpture was presented to Louis XIV as Aesculapius but restored as Zeus, ca. 1686, by Pierre Granier, who added the upraised right arm brandishing the thunderbolt. Marble, middle 2nd century CE. Formerly in the 'Allée Royale', (Tapis Vert) in the Gardens of Versailles, now conserved in the Louvre Museum (Official on-line catalogue)\n↑ Larousse Desk Reference Encyclopedia, The Book People, Haydock, 1995, p. 215.\nRetrieved from \"https://simple.wikipedia.org/w/index.php?title=Zeus&oldid=7055462\"\nCategory: Twelve OlympiansHidden categories: Articles having different image on Wikidata and WikipediaCommons category link is on Wikidata\nNavigation menu\nSearch\n\n"
    }
   ],
   "source": [
    "# Function test\n",
    "url = ['https://simple.wikipedia.org/wiki/Zeus']\n",
    "print(extract_text(url, export_as_file=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning Model\n",
    "This function is used to finetune the model based on the current latest dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(dataset):\n",
    "    '''\n",
    "\n",
    "    Function to finetune the model and save the trained model every checkpoint on the checkpoint folder.\n",
    "\n",
    "    @dataset: Path to the training data (TXT) with minimum 1024 tokens\n",
    "    @model_name: The name of the model: 124M, 355M, etc.\n",
    "    @learning_rate: The learning rate of the model\n",
    "\n",
    "    return: None\n",
    "\n",
    "    '''\n",
    "    # Parameters\n",
    "    STEPS = 1000\n",
    "    MODEL_NAME = '124M'\n",
    "    LEARNING_RATE = 0.0001\n",
    "\n",
    "    # Clear session graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Initialize training session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Finetune the model\n",
    "    gpt2.finetune(\n",
    "        sess,\n",
    "        dataset=dataset,  # Dataset CSV file\n",
    "        steps=STEPS,\n",
    "        model_name=MODEL_NAME,  # Model name: 124M, 355M, etc.\n",
    "        model_dir='models',\n",
    "        combine=50000,\n",
    "        batch_size=1,\n",
    "        learning_rate=LEARNING_RATE,  # Learning rate\n",
    "        accumulate_gradients=5,\n",
    "        restore_from='latest',  # Start training the model from the latest model\n",
    "        run_name='trained_model',  # Name of the trained model\n",
    "        checkpoint_dir='checkpoint',  # Directory to save the model\n",
    "        sample_every=250,\n",
    "        sample_length=500,  # Number of token generated\n",
    "        sample_num=1,\n",
    "        multi_gpu=False,\n",
    "        save_every=250,\n",
    "        print_every=10,\n",
    "        max_checkpoints=1,\n",
    "        use_memory_saving_gradients=False,\n",
    "        only_train_transformer_layers=False,\n",
    "        optimizer='adam',\n",
    "        overwrite=True  # Overwrite the current model when training\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the finetuning model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = ''\n",
    "# finetune_model(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text\n",
    "This functions is used to generate the text based on some input from the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(outline_to_length):\n",
    "    '''\n",
    "\n",
    "    Function to generate the text.\n",
    "\n",
    "    @outline_to_length: A 2D array containing the list of outline and the length desired\n",
    "        [[outline, length],\n",
    "        [outline, length],\n",
    "        [outline, length]]\n",
    "\n",
    "    return: List of generated text\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Clear session graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Initialize TensorFlow session\n",
    "    sess = gpt2.start_tf_sess()\n",
    "\n",
    "    # Create an empty list to store lists\n",
    "    essay = []\n",
    "\n",
    "    # Loop over the list\n",
    "    for record in outline_to_length:\n",
    "        prefix = record[0]  # The first sentence of the paragraph\n",
    "        length = record[1]  # The length of the paragraph (max: 1023)\n",
    "\n",
    "        text = gpt2.generate(\n",
    "            sess,\n",
    "            run_name='trained_model',\n",
    "            checkpoint_dir='checkpoint',\n",
    "            model_name=None,\n",
    "            model_dir='models',\n",
    "            sample_dir='samples',\n",
    "            return_as_list=True,  # Return as list of string\n",
    "            truncate=None,\n",
    "            destination_path=None,\n",
    "            sample_delim='\\n' + '=' * 20 + '\\n\\n',\n",
    "            prefix=prefix,\n",
    "            seed=None,\n",
    "            nsamples=1,  # Number of sample to be generated\n",
    "            batch_size=1,\n",
    "            length=length,\n",
    "            temperature=0.7,\n",
    "            top_k=0,\n",
    "            top_p=0.0,\n",
    "            include_prefix=True\n",
    "        )\n",
    "\n",
    "        essay += text\n",
    "\n",
    "        # Add double newline\n",
    "        essay += ['\\n\\n']\n",
    "\n",
    "    return ''.join(essay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_outline_to_length = [[]]\n",
    "# print(generate_text(test_outline_to_length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrasing Text\n",
    "This function is used to paraphrase the sentences to avoid direct plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Check\n",
    "This function is used to check and correct any grammatical error in the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}